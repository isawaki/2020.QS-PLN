{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-QS PLN Atividade Aula 07.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMvPDu47k19Ft9iqthXpCUM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2020.QS-PLN/blob/main/2020_QS_PLN_Atividade_Aula_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qftignX4cZmx"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2020.QS]**\n",
        "Prof. Alexandre Donizeti Alves\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5-jHI3Zcf06"
      },
      "source": [
        "### **Atividade Aula 07 [Normalização de Textos]**\n",
        "**Pré-processamento de Texto**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z0lg6zTScllq"
      },
      "source": [
        "Temos um corpus de texto que está em formato impróprio. Nesta atividade, vocês devem realizar todas as etapas de pré-processamento que foram discutidas anteriormente para obter algum significado do texto."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtZ8ktXgesZJ"
      },
      "source": [
        "O corpus do texto, **file.txt**, pode ser encontrado no mesmo diretório desta atividade no GitHub.\n",
        "\n",
        "Depois de baixar o arquivo, coloque-o no mesmo diretório do notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8Cdsxvce8rX"
      },
      "source": [
        "Realize as seguintes etapas para implementar esta atividade:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gzVYlYxdfNd-"
      },
      "source": [
        "**1.  Importe as bibliotecas necessárias**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyjTQfOmfYjE"
      },
      "source": [
        "# importe as bibliotecas necessárias\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dpMdEZufcu-"
      },
      "source": [
        "**2.   Carregue o corpus do texto para uma variável**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6i1en-ILfp_o"
      },
      "source": [
        "# carregue o corpus do texto para uma variavel\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Galo0Ispfxpn"
      },
      "source": [
        "**3. Aplique o processo de tokenização ao corpus do texto e imprima os primeiros 20 tokens**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g5dTDfjff8Gm"
      },
      "source": [
        "# tokenizacao\n",
        "\n",
        "\n",
        "# imprimir os primeiros 20 tokens\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARwvdQjFgGq3"
      },
      "source": [
        "**4. Aplique a correção ortográfica em cada token e imprima os 20 tokens iniciais corrigidos, bem como o corpus do texto corrigido**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJ4DLxYcgOBp"
      },
      "source": [
        "# correcao ortografica (crie uma funcao)\n",
        "\n",
        "\n",
        "# imprimir os 20 tokens iniciais corrigidos\n",
        "\n",
        "\n",
        "# imprimir o texto corrigido\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRIeqyTfhDuz"
      },
      "source": [
        "**5. Aplique PoS tags a cada um dos tokens corrigidos e imprima-os**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oq4kUk3KhQkr"
      },
      "source": [
        "# imprimir o PoS tags de cada um dos tokens corrigidos\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBY4D5bShiYI"
      },
      "source": [
        "**6. Remova as *stop words* da lista de tokens corrigida e imprima os 20 tokens iniciais**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJQsmJk2hu3_"
      },
      "source": [
        "# remover as stop words (crie uma funcao)\n",
        "\n",
        "\n",
        "# imprimir os 20 tokens iniciais\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lsxGtlHXh7_P"
      },
      "source": [
        "**7. Aplique *stemming* e lematização à lista de tokens corrigida e, em seguida, imprima os 20 tokens iniciais**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caD5lVh_iFLQ"
      },
      "source": [
        "# stemming\n",
        "\n",
        "\n",
        "# imprimir os 20 tokens iniciais\n",
        "\n",
        "\n",
        "# lematizacao\n",
        "\n",
        "\n",
        "# imprimir os 20 tokens iniciais\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGcuBn4_irk-"
      },
      "source": [
        "**8. Detecte os limites das sentenças no corpus de texto fornecido e imprima o número total de sentenças**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pS58kxMtiyet"
      },
      "source": [
        "# detectar os limites das sentencas no corpous de texto fornecido\n",
        "\n",
        "\n",
        "\n",
        "# imprimir o numero total de sentencas\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}