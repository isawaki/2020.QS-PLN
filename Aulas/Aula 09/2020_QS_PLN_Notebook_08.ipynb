{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-QS PLN Notebook 08.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2020.QS-PLN/blob/main/2020_QS_PLN_Notebook_08.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Q2Bo6Sill63"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2020.QS]**\n",
        "\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rhi4TLwolnvK"
      },
      "source": [
        "##**Modelo de Linguagem com N-gramas**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYPYP6mVSTVk"
      },
      "source": [
        "### **Bibliotecas**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kFeFaUQEtEqC"
      },
      "source": [
        "# expressoes regulares\n",
        "import re\n",
        "\n",
        "# cria um dicinario com a frequencia dos termos em um iterable\n",
        "from collections import Counter\n",
        "\n",
        "## subsequencias de um iterable\n",
        "from itertools import islice\n",
        "\n",
        "# numeros e sequencias aleatoreas\n",
        "import random"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1K0PgaCSx_U"
      },
      "source": [
        "### **Funções principais**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SA9JstDuVaL"
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+\"       # raw string\n",
        "#regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ0-9]+\"   # raw string\n",
        "\n",
        "# usa expressoes regulares para quebrar um texto em tokens\n",
        "def get_tokens(fileName):\n",
        "  # leitura do documento\n",
        "  with open(fileName,'r') as document:\n",
        "     content  = document.read()  # devolve um vetor contendo as linhas do arquivo\n",
        "     content  = content.lower()\n",
        "\n",
        "  Words    = re.findall(regex, content)\n",
        "\n",
        "  return(Words)\n",
        "\n",
        "# similar ao get_tokens, mas removindo elementos da lista de stopwords\n",
        "def get_tokens_without_stopwords(fileName,stopwordsName=\"/content/stopwords.txt\"):\n",
        "   # leitura do documento\n",
        "   with open(fileName,'r') as document:\n",
        "      content  = document.read()  # devolve um vetor contendo as linhas do arquivo\n",
        "      content  = content.lower()\n",
        "\n",
        "   # leitura das stopwords\n",
        "   with open(stopwordsName,'r') as stopwordsfile:\n",
        "      stopwords = set([])\n",
        "      for s in stopwordsfile.readlines():                                                                                                                                                     \n",
        "        stopwords.add(s.strip().lower())\n",
        "\n",
        "   # remove as stopwords\n",
        "   Words    = [w for w in re.findall(regex, content) if w not in stopwords]\n",
        "\n",
        "   return(Words)\n",
        "\n",
        "# retirado de um exemplo na internet\n",
        "def window(seq, n=2):\n",
        "    \"Retorna uma janela deslizante (de tamanho n) sobre a sequencia seq\"\n",
        "    \"   s -> (s0,s1,...s[n-1]), (s1,s2,...,sn), ...                   \"\n",
        "    it = iter(seq)\n",
        "    result = tuple(islice(it, n))\n",
        "    if len(result) == n:\n",
        "        yield result    \n",
        "    for elem in it:\n",
        "        result = result[1:] + (elem,)\n",
        "        yield result\n",
        "\n",
        "# isa o Counter para contar a frequencia de unigramas e bigramas\n",
        "def ngrams(Words):\n",
        "    \"Retarna a contagem de unigramas e bigramas a partir da lista de palavras\"\n",
        "  \n",
        "    # Conta Unigramas (utilizando o counter de collections)\n",
        "    Unigrams = Counter(Words)\n",
        "\n",
        "    # windows retora uma janela delizante de tamanho 2\n",
        "    Bigrams  = Counter(window(Words,2))\n",
        "\n",
        "    return(Unigrams,Bigrams)\n",
        "\n",
        "# funcao auxiliar para calcular as probabilidades\n",
        "BigramProbabilities = lambda w1, w2 : bigrams [ (w1,w2) ] / unigrams[ w1 ]\n",
        "\n",
        "# aplica o score em uma lista de sentencas\n",
        "def score(phrases):\n",
        "\n",
        "    # loop sobre todas as sentencas de teste\n",
        "    for phrase in phrases:\n",
        "        Words = re.findall(regex, phrase)\n",
        "        P = float(1.0)\n",
        "        for w_0, w_1 in window(Words,2):\n",
        "            P = P * BigramProbabilities(w_0, w_1)\n",
        "\n",
        "        print ( \"{1:.20f} : Sentença: {0}\".format( phrase, P ) ) "
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mI3YD1xOTl8a"
      },
      "source": [
        "### **Testando o Modelo**\n",
        "\n",
        "Cria uma sequência de sentenças e um modelo de bigramas baseado no livro de **Machado de Assis**, e aplica a função score na lista de sentenças"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CVj8TEvcwXE4",
        "outputId": "c962d3f2-85e5-444a-cbd9-d2337619f4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sentencas = [\"ele é\",\n",
        "             \"ele é uma\", \n",
        "             \"ele é uma pessoa\", \n",
        "             \"ele é uma pessoa de\", \n",
        "             \"ele é uma pessoa de verdade\"]\n",
        "\n",
        "words = get_tokens(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "score(sentencas)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02647657841140529586 : Sentença: ele é\n",
            "0.00069189664838167149 : Sentença: ele é uma\n",
            "0.00000842133213707000 : Sentença: ele é uma pessoa\n",
            "0.00000050654629395910 : Sentença: ele é uma pessoa de\n",
            "0.00000000051863038186 : Sentença: ele é uma pessoa de verdade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbNTzxnmT_na"
      },
      "source": [
        "Repetimos o processo, agora considerando todas as obras de Machado de Assis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D8OnobVXCM3D",
        "outputId": "9fc497ab-b306-4cbd-9c6c-60f77fb93c29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "sentencas = [\"ele é\",\n",
        "             \"ele é uma\", \n",
        "             \"ele é uma pessoa\", \n",
        "             \"ele é uma pessoa de\", \n",
        "             \"ele é uma pessoa de verdade\"]\n",
        "\n",
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "score(sentencas)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.02488038277511961729 : Sentença: ele é\n",
            "0.00093406050182903407 : Sentença: ele é uma\n",
            "0.00000825483405278844 : Sentença: ele é uma pessoa\n",
            "0.00000046590235609081 : Sentença: ele é uma pessoa de\n",
            "0.00000000050723310908 : Sentença: ele é uma pessoa de verdade\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orahrwRdUHpn"
      },
      "source": [
        "### **Probabilidade da próxima palavra**\n",
        "\n",
        "Usamos o modelo de bigrama para calcular quais as palavras mais prováveis."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGwISM_1EiHy"
      },
      "source": [
        "def next_prob(phrase,n=5):\n",
        "    # quebre a sentenca em palavras\n",
        "    Words = re.findall(regex, phrase)\n",
        "\n",
        "    # calcula as probabilidades de todas as palavras em que o bigrama eh w1 e armazena em prob\n",
        "    probs = {w2 : BigramProbabilities(w1,w2) for (w1,w2) in bigrams.keys() if w1 == Words[-1] }\n",
        "\n",
        "    # ordena e imprime as n mais relevantes\n",
        "    for w, p in islice(sorted(probs.items(), key = lambda item: item[1], reverse=True),n):\n",
        "        print ( \"{0} -> {1} ({2:.2f}%)\".format( phrase, w.upper(), p*100 ) )   "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55a4_4VWUbvC"
      },
      "source": [
        "**Teste da função `next_prob`**\n",
        "\n",
        "O usuário digita frases e modelo lista as 5 palavras mais prováveis de acordo com o modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltyUH_zcLLL6",
        "outputId": "e6a2f324-89d1-4c29-8c5c-b494a3d59ce7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "words = get_tokens(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "\n",
        "phrase = input(\"\\nDigite uma frase: \")\n",
        "\n",
        "while (phrase != \"\"):\n",
        "    next_prob(phrase)\n",
        "    phrase = input(\"\\nDigite uma frase:\")\n",
        "\n",
        "# frase: ele é uma pessoa\n",
        "# frase: estudar\n",
        "# frase: a semana que"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Digite uma frase: ele é uma pessoa\n",
            "ele é uma pessoa -> QUE (28.57%)\n",
            "ele é uma pessoa -> DE (6.02%)\n",
            "ele é uma pessoa -> A (4.51%)\n",
            "ele é uma pessoa -> É (2.26%)\n",
            "ele é uma pessoa -> NO (2.26%)\n",
            "\n",
            "Digite uma frase:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvF9UFUYU481"
      },
      "source": [
        "**Teste da função `next_prob`**\n",
        "\n",
        "O usuário digita frases e modelo lista as 5 palavras mais prováveis de acordo com o modelo, **sem considerar as *stopwords***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEzurfRyikTO",
        "outputId": "be131332-0030-4de9-b9b5-d12b1e969629",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "words = get_tokens_without_stopwords(\"/content/A-Semana-Machado-de-Assis.txt\")\n",
        "\n",
        "unigrams, bigrams = ngrams(words)\n",
        "\n",
        "phrase = input(\"\\nDigite uma frase: \")\n",
        "\n",
        "while (phrase != \"\"):\n",
        "    next_prob(phrase)\n",
        "    phrase = input(\"\\nDigite uma frase:\")\n",
        "\n",
        "# frase: que\n",
        "# frase: Rio"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Digite uma frase: Rio\n",
            "\n",
            "Digite uma frase:que\n",
            "\n",
            "Digite uma frase:rio\n",
            "rio -> JANEIRO (54.70%)\n",
            "rio -> GRANDE (15.38%)\n",
            "rio -> BRANCO (5.98%)\n",
            "rio -> CLARO (2.56%)\n",
            "rio -> NEWS (1.71%)\n",
            "\n",
            "Digite uma frase:RIO\n",
            "\n",
            "Digite uma frase:rio\n",
            "rio -> JANEIRO (54.70%)\n",
            "rio -> GRANDE (15.38%)\n",
            "rio -> BRANCO (5.98%)\n",
            "rio -> CLARO (2.56%)\n",
            "rio -> NEWS (1.71%)\n",
            "\n",
            "Digite uma frase:a\n",
            "\n",
            "Digite uma frase:de\n",
            "\n",
            "Digite uma frase:estudar\n",
            "estudar -> SOLUÇÃO (10.00%)\n",
            "estudar -> MEIO (10.00%)\n",
            "estudar -> DESCOBRIR (10.00%)\n",
            "estudar -> PROBLEMA (10.00%)\n",
            "estudar -> COISAS (10.00%)\n",
            "\n",
            "Digite uma frase:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tYpFk2qsVt_b"
      },
      "source": [
        "### **Classe NGrams**\n",
        "\n",
        "- Reorganiza e empacota as funções anteriores em uma classe\n",
        "\n",
        "- O parâmetro 'max_n' corresponde ao valor máximo de elementos no modelo *ngram*\n",
        "\n",
        "- Uma única tabela `Counter` é usada, pois a própria chave já contém a informação do número de *grams*\n",
        "\n",
        "- O método `probability` trata n-gramas que não aparecem na base\n",
        "\n",
        "- O método `generate` pega a primeira palavra acima de um `threshold` em uma lista de unigramas embaralhada"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJ-T2YrZothG"
      },
      "source": [
        "class NGrams(object):\n",
        "\n",
        "    def __init__(self,max_n,Words=None):\n",
        "        self.max_n   = max_n\n",
        "        self.Counts  = Counter()\n",
        "\n",
        "        if Words is not None:\n",
        "            self.update(Words)\n",
        "\n",
        "    def update(self, Words):\n",
        "\n",
        "        # conta os unigram, bigram, trigram, ..., ngram\n",
        "        # e armazena na mesma estrutura\n",
        "        for i in range(1,self.max_n+1):\n",
        "            self.Counts.update(window(Words,i))\n",
        "\n",
        "        # Caso especial: tupla vazia (util para o metodo 'probability')\n",
        "        # O valor eh igual ao numero de palavras\n",
        "        self.Counts[()] += len(Words)\n",
        "\n",
        "    # Calcula a probabilidade para a frase: Words\n",
        "    def probability(self, Words):\n",
        "        if len(Words) <= self.max_n:\n",
        "            return self._probability(Words)\n",
        "        else:\n",
        "            P = 1\n",
        "            for i in range(len(Words) - self.max_n + 1):\n",
        "                ngram = Words[i:i + self.max_n]\n",
        "                P     = P * self._probability(ngram)\n",
        "            return P\n",
        "\n",
        "    # Calcula a aproximacao para o n-grama usando seu prefixo\n",
        "    def _probability(self, ngram):\n",
        "        ngram        = tuple(ngram)\n",
        "        ngram_count  = self.Counts[ngram]\n",
        "        prefix_count = self.Counts[ngram[:-1]]\n",
        "\n",
        "        # Se uma tupla (n-grama) nao for observada devolvemos zero\n",
        "        if ngram_count and prefix_count:\n",
        "            return ngram_count / prefix_count\n",
        "        else:\n",
        "            return 0.0\n",
        "\n",
        "        # Geracao de frases de 'n_words'\n",
        "    def generate(self, n_words, threshold = random.random()):\n",
        "\n",
        "        # cria uma lista de unigrams\n",
        "        unigrams = [ngram for ngram in self.Counts.keys() if len(ngram) == 1]\n",
        "\n",
        "        # Tentamos gerar frases \n",
        "        words = []\n",
        "        \n",
        "        while len(words) < n_words:\n",
        "            # o prefixo para o proximo n-grama\n",
        "            if self.max_n == 1:\n",
        "                prefix = ()\n",
        "            else:\n",
        "                prefix = tuple(words[-self.max_n + 1:])\n",
        "           \n",
        "            total     = 0.0\n",
        "            random.shuffle(unigrams)\n",
        "            for unigram in unigrams:\n",
        "                total += self._probability(prefix + unigram)\n",
        "                if total >= threshold:\n",
        "                    words.extend(unigram)\n",
        "                    break\n",
        "            \n",
        "            # Se nao for possivel criar uma frase  \n",
        "            if total == 0.0:\n",
        "                raise RuntimeError('impossible sequence')\n",
        "\n",
        "        return(words)\n"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7GauQRUsXS48"
      },
      "source": [
        "### **Teste geração de sentenças**\n",
        "\n",
        "Usamos os ngramas de todas as obras de Machado de Assis com 1, 2 e 5 gramas\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fncG3lq10kuX"
      },
      "source": [
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM9x7HJItyWQ",
        "outputId": "f8559536-5bea-4715-d63b-2aea2d788024",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# unigrama\n",
        "ng = NGrams(1, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "iaiá santa libra matar mesmo doutor com não nada à méxico depois metia igreja de chamar-se que acudiu e duro coveiros o apatia se os de o seguramente meias disse\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egZDaUI0uAxt",
        "outputId": "e5db92e9-e2e0-4142-a7ee-6487f3ab17a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# bigrama\n",
        "ng = NGrams(2, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "de termos um viajante entrou no norte com o folhetim não possa a graça pertence-me aquela cor que ernesto costumava ele mesmo como para o sr correia disse ele no\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0ogci0q11RX",
        "outputId": "2e36ad07-2b78-447e-a60d-0e18fbea1498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# 5-grama\n",
        "ng = NGrams(5, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "idade perguntou-me impaciente mas papai por que é que não nos visita há tanto tempo creio que tem andado mais achacada dos seus reumatismos este ano tem feito muito frio\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkZnfLqPX9DY"
      },
      "source": [
        "Repetimos o teste, agora usando os n-gramas do **discurso do Bolsonaro na ONU**. Observem a dependência do corpus usado\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZ-vHYVkLBFQ"
      },
      "source": [
        "words = get_tokens(\"/content/discurso_bolsonaro.txt\")"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xa82J5ExLIXf",
        "outputId": "dba21495-9be5-44c3-d5b5-1b5baa435ebe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "ng = NGrams(3, Words=words)\n",
        "print(\" \".join(ng.generate(30)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "outros e esses territórios são enormes a reserva ianomâmi sozinha conta com aproximadamente mil km o equivalente ao tamanho de portugal ou da hungria embora apenas mil índios vivam nessa\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMW9vrpeYPwE"
      },
      "source": [
        "### **Geração de sentenças com pontuação**\n",
        "\n",
        "Considera os caracteres de pontuação e números como sendo gramas válidos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-yJZtesOLSx",
        "outputId": "4869c5f0-39ff-422e-f522-470b28123e30",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+|[,\\.-?]|[0-9]+\"   # raw string\n",
        "\n",
        "words = get_tokens(\"/content/Todas-as-obras-Machado-de-Assis.txt\")\n",
        "\n",
        "ng = NGrams(5, Words=words)\n",
        "print(\" \".join(ng.generate(10)))"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "e acabando na questão espanhola . há serrilhas de todas\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0AOUZ2hP8Rj",
        "outputId": "64c83389-6ba8-4634-d671-7bdae179c4e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "regex = r\"[-'a-zA-ZÀ-ÖØ-öø-ÿ]+|[,\\.-?]|[0-9]+\"   # raw string\n",
        "\n",
        "words = get_tokens(\"/content/discurso_bolsonaro.txt\")\n",
        "\n",
        "ng = NGrams(3,Words=words)\n",
        "print(\" \".join(ng.generate(50)))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a amazônia é patrimônio da humanidade e um equívoco , como o cacique raoni , são usados como peça de manobra por governos estrangeiros na sua guerra informacional para avançar seus interesses na amazônia despertaram nosso sentimento patriótico . é inadmissível que , já nos anos 6 0 , agentes\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}